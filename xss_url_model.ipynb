{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xsseed archive URL\n",
    "url = \"http://www.xssed.com/archive/page={}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ansh\\capstone\\scraper\\xss_url_model.ipynb Cell 3\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# we go through every page of the archive and collect all the links \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# for websites vulnerable to XSS attacks\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1530\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# get html and javascript content\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# we use beautiful soup library for web scraping\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ansh/capstone/scraper/xss_url_model.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(r\u001b[39m.\u001b[39mcontent,\u001b[39m\"\u001b[39m\u001b[39mhtml5lib\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "mirrors = []\n",
    "# we go through every page of the archive and collect all the links \n",
    "# for websites vulnerable to XSS attacks\n",
    "for i in range(1,1530):\n",
    "    # get html and javascript content\n",
    "    r = requests.get(url.format(i))\n",
    "    # we use beautiful soup library for web scraping\n",
    "    soup = BeautifulSoup(r.content,\"html5lib\")\n",
    "    # using soup we find all 'a' tags\n",
    "    # 'a' tags are\n",
    "    for link in soup.find_all('a'):\n",
    "        if \"mirror\" in link.get(\"href\"):\n",
    "            mirrors.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.xssed.com{}\"\n",
    "malicious_urls = []\n",
    "mirror_urls = []\n",
    "\n",
    "for m in mirrors:\n",
    "    mirror = url.format(m)\n",
    "    r = requests.get(mirror)\n",
    "    soup = BeautifulSoup(r.content,\"html5lib\")\n",
    "    malicious_urls.append(soup.select(\"#contentpaneOpen > table > tbody > tr:nth-child(4) > th\")[0].text[5:])\n",
    "    mirror_urls.append(soup.select(\"#contentpaneOpen > table > tbody > tr:nth-child(5) > th > a\")[0].get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename,strings):\n",
    "    with open(filename, \"w\") as file:\n",
    "        for string in strings:\n",
    "            file.write(string + \"\\n\")\n",
    "\n",
    "write_file(\"mirrors.txt\",mirror_urls)\n",
    "write_file(\"malicious_urls.txt\",malicious_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_list(filename):\n",
    "    lines = []\n",
    "    with open(filename,'r') as file:\n",
    "        for line in file:\n",
    "            cleaned_line = line.strip()\n",
    "            lines.append(cleaned_line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "data = []\n",
    "def generate_csv():\n",
    "    malicious = file_to_list(\"malicious_urls.txt\")\n",
    "    benign = file_to_list(\"benign_urls.txt\")\n",
    "    for m in malicious:\n",
    "        data.append([m,1])\n",
    "    for b in benign:\n",
    "        data.append([b,0])\n",
    "    random.shuffle(data)\n",
    "\n",
    "    with open(\"urls.csv\",mode=\"w\",newline=\"\") as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        for row in data:\n",
    "            print(row)\n",
    "            csv_writer.writerow(row)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    with open(filename,mode=\"r\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        data = []\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "\n",
    "def duplicate(url):\n",
    "    patterns = [r'<<', r'>>', r'%3C%3']\n",
    "    total_occurrences = 0\n",
    "    for pattern in patterns:\n",
    "        occurrences = len(re.findall(pattern, url))\n",
    "        total_occurrences += occurrences\n",
    "    return total_occurrences\n",
    "\n",
    "def special(url):\n",
    "    substrings = [\"“, “”>\", \"“>\", \"“/>\"]\n",
    "    total_occurrences = 0\n",
    "    for substring in substrings:\n",
    "        total_occurrences += url.count(substring)\n",
    "    return total_occurrences\n",
    "\n",
    "def html_tags(url):\n",
    "    pattern = r'<[^>]+>'\n",
    "    html_tags = re.findall(pattern, url)\n",
    "    return len(html_tags)\n",
    "\n",
    "def cookie(url):\n",
    "    pattern = r'document\\.cookie'\n",
    "    if re.search(pattern, url):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def redirections(url):\n",
    "    pattern = r'window\\.(location\\.href|history\\.back|navigate)'\n",
    "    if re.search(pattern, url):\n",
    "       return 1\n",
    "    return 0\n",
    "\n",
    "def extract_features(url):\n",
    "    # attackers use url encoding to hide payloads / attack vectors\n",
    "    # hence we decode it\n",
    "    decoded_url = urllib.parse.unquote(url)\n",
    "\n",
    "    return [len(decoded_url), 1 if decoded_url == url else 0 ,html_tags(decoded_url),duplicate(decoded_url),special(decoded_url),cookie(decoded_url),redirections(decoded_url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[\"number_of_characters\",\"url_encoding\",\"html_tags\",\"duplicate_characters\",\"cookie_requests\",\"redirections\",\"target\"]]\n",
    "\n",
    "with open(\"urls.csv\",mode=\"r\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        new_row = extract_features(row[0])\n",
    "        new_row.append(int(row[1]))\n",
    "        dataset.append(new_row)\n",
    "file.close()\n",
    "\n",
    "with open(\"urls_features_data.csv\",mode=\"w\",newline=\"\") as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    for row in dataset:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv(\"urls_features_data.csv\")\n",
    "X = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9890582624146638\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7069\n",
      "           1       1.00      0.97      0.98      3624\n",
      "\n",
      "    accuracy                           0.99     10693\n",
      "   macro avg       0.99      0.98      0.99     10693\n",
      "weighted avg       0.99      0.99      0.99     10693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9890582624146638\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7069\n",
      "           1       1.00      0.97      0.98      3624\n",
      "\n",
      "    accuracy                           0.99     10693\n",
      "   macro avg       0.99      0.98      0.99     10693\n",
      "weighted avg       0.99      0.99      0.99     10693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=1)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9890582624146638\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7069\n",
      "           1       1.00      0.97      0.98      3624\n",
      "\n",
      "    accuracy                           0.99     10693\n",
      "   macro avg       0.99      0.98      0.99     10693\n",
      "weighted avg       0.99      0.99      0.99     10693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=42)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
